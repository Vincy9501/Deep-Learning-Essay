# 1. 引入

回想一下我们之前用的例子，手写数字识别。

我们的输入是图像的单个像素，输出是我们试图分类的模式。
![[Pasted image 20230211185110.png]]

对于中间的层，我们将有两个卷积层、两个池化层和两个全连接层。

对于输入，虽然我们的输入是单个像素，但是数字设备中的每个图像都存储为像素值矩阵，这被称为通道。

使用典型的数码相机，每个图像有三个通道：红色、绿色和蓝色，RGB。可以想象为三个相互堆叠的二维矩阵。

简单起见，我们假设我们的输入只有一个通道，即图像的亮度。每个像素的值以八位表示。也就是说像素值的范围为0-255（暗-亮）。

## 1.1 卷积层

对于卷积层，这个层和整个网络的名称都来自于卷积运算符。通俗地说是一种数学组合。换句话说，两个函数的点积产生第三个函数。

在CNN，此操作在所谓的特征检测器、过滤器或最常见的内核中实现。可以将内核视为一个迷你矩阵。比输入小几个数量级。

在卷积运算中，内核在输入图像上移动，获取两个矩阵的点积并将值保存到一个新矩阵中。称为原始图像的特征图。

![[Pasted image 20230211190009.png]]

问题：如何检测到任何特征的呢？

如果使用特定配置中的值初始化内核，它们可用于转换输入图像并找到各种模式。

以下图为例，当加载适当的值并与输入图像进行卷积时，会产生突出照片各个边缘的输出。

![[Pasted image 20230211190204.png]]

内核本质上是进行快速计算和产生新输出的方法。在这种情况下我们使用图像来实现。突出显示效果或功能。

一开始，我们使用的内核类型非常简单且更具有几何性，检测如边缘、角以及简单形状和图案。此外，每个卷积层都可以有多个内核，这些内核可以生成自己的多个特征图。

对于本例，第一层的六个内核用于检测简单的模式，如水平线、角等。对于我们特征图中的每个卷积像素，还应用了非线性函数，在本例中为ReLU。
![[Pasted image 20230211190604.png]]
每个通道有六个特征图，在这种情况下RGB图像有18个。

![[Pasted image 20230211190815.png]]

## 1.2 池化层

卷积层的下一层是池化层，主要功能：
- 对我们的特征图进行下采样（缩小图像）。
- 保留最重要的部分并丢弃其余部分，降低过拟合率。
- 图像的空间大小减小，可以在后面的层中加快计算速度。

我们的网络实现的池化类型是最大池化。其中我们采用另一个内核，并将其滑过我们的输入特征图。该区域中最大的像素值就是保存到我们新的输出特征图中的值。
![[Pasted image 20230211191304.png]]


还有一个最大池化层用于减少全连接层之前特征图的空间维度。

## 1.3 分类器

特征提取之后我们仍需要对特征进行分类。分类的工作由全连接层完成。类似于前馈网络。

除了现在我们对这些感知器层的输入，是我们输入的高级抽象特征而不是原始的输入像素。

在这个例子中第一个全连接层有120个神经元，第二层100个。正如这些足以对数字进行高度准确的正确分类。

反向传播同样会影响卷积层和池化层。

![[Pasted image 20230211192427.png]]



但是在自然语言处理等任务中CNN并不出色，因为这些任务需要记忆。

# 2. 深入了解

我们在上一节得知，有一个内核，也称过滤器在图上移动。在数学上，它做了以下几件事：
1. 将特征和图像对齐
2. 每个图像的像素乘以特征像素
3. 加起来
4. 除以特征中的像素总数

![[Pasted image 20230211193253.png]]

![[Pasted image 20230211193340.png]]

对于卷积层，我们重复运用过滤器的特征，获得特征图：

![[Pasted image 20230211193713.png]]

而对于池化层，它是用于缩小图像的，我们会得到一个缩小的有特征的图像：

![[Pasted image 20230211193756.png]]

另外，我们会通过ReLU将每一个负数转变为0。

![[Pasted image 20230211193942.png]]

我们将以上几层堆叠起来，会获得：

![[Pasted image 20230211194020.png]]

最后会进行投票，决定分类：

![[Pasted image 20230211194209.png]]

最后我们将这些层叠加起来获得如下流程：

![[Pasted image 20230211194255.png]]

# 3. 实战

PyTorch基础知识：CNN主要代码
import torch.nn as nn

CNN模块：
- 卷积层 nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)
- 池化层 nn.MaxPool1d(kernel_size=2, stride=2)
-  BN层 nn.BatchNorm1d(num_features=16. momentum=0.1)
-  激活函数 nn.ReLU()
-  全连接层 nn.Linear(in_features=200, out_features=4)
-  Softmax nn.Softmax(dim=1)
-  Flatten nn.Flatten()

网络模型参数更新:
- optimizer = torch.optim.Adam(net.parameters(), Ir=0.001)
- 损失反向传播: loss.backward()
- 模型参数更新: optimizer.step()
- 模型梯度清零: optimizer.zero_ grad()

![[Pasted image 20230212170018.png]]

数据集：所使用的数据源于凯斯西储轴承数据中心所公布的公用轴承数据集，该数据集模拟了常见的轴承故障:内圈故障、外圈故障和滚动体故障。实验台主要包括了电机、测力计及各类传感器，使用加速度传感器采集不同工况下的振动信号。

## 3.1 创建数据集

![[Pasted image 20230212170334.png]]

## 3.2 构建模型

![[Pasted image 20230212170506.png]]

## 3.3 优化模型

优化用来做梯度更新的。

![[Pasted image 20230212170854.png]]

## 3.4 评估模型

![[Pasted image 20230212170959.png]]



# 参考文献

- [Convolutional Neural Networks Explained (CNN Visualized)](https://www.youtube.com/watch?v=pj9-rr1wDhM)
- [ How Convolutional Neural Networks work](https://www.youtube.com/watch?v=FmpDIaiMIeA)
- [Convolutional Neural Network from Scratch | Mathematics & Python Code](https://www.youtube.com/watch?v=Lakz2MoHy6o)
- [CNN卷积神经网络与项目实战之图片分类器](https://www.bilibili.com/video/BV1dT4y1U7VG?p=2&vd_source=9ea40c1ac510f1e604555a3c8278ff94)
- [机械故障智能诊断简介与CNN实战解析](https://www.bilibili.com/video/BV1xY411j7dn/?spm_id_from=333.337.search-card.all.click&vd_source=9ea40c1ac510f1e604555a3c8278ff94)
