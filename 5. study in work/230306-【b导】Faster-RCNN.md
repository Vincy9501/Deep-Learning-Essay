# 1. 概念

比如说在图片上框出一只猫，画出这个框需要四个参数：
分别是中心点的x轴、y轴坐标、框的高和宽

- Faster-RCNN会把输入进来的图片resize到最小边是600的shape上，防止失真，长宽比保持不变。
- 输入到主干特征提取网络中，假如输入图片是600 x 800，那么就会获得一个38 x 50的特征层，相当于把图片分为38 x 50的网格，每个网格存在若干先验框。
- 利用**RPN区域建议网络**，就能获得先验框的调整参数，以及先验框内是否包含物体，此时我们就获得了建议框。
- 利用**建议框在特征层上截取**，截取不同特征层反映原图不同位置。
- 截取内容**传入ROI pooling层**中，会resize各部分到一样大小。
- 利用**分类与回归网络**判断截取内容是否包含目标，并对建议框进行调整。
- 调整后的结果就是预测结果。

总的来说可以分为两步：粗筛、精调

![[Pasted image 20230306094606.png]]

Feature Map：38 x 38  x 1024，图片经过特征提取之后的特征。

Feature Map左分支：建议框网络，两支分别进行1x1卷积，一个通道数为9 x 2， 另一个为9 x 4，这一步是为了判断先验框是否包含物体。然后对先验框进行调整，调整成建议框。9 x 2，2一个是代表背景的概率，一个是代表内部有物体的概率；9 x 4，4是4个调整参数。

然后获得建议框，会与FM结合传入ROIPooling层。

建议框大小是不定的，利用建议框对共享特征层截取的时候，获取的局部特征层大小也不定。

ROIPooling层会对局部特征层分区域池化，之后获得的局部特征层大小就一样了。

依次进行分类预测和回归预测。回归预测结果会直接对建议框进行调整，然后获得最终预测框；分类预测结果会判断建议框内部是否真实包含物体并且判断物体种类。

# 2. Backbone

例子中使用得是Resnet50，有两个基本的块，**分别名为Conv Block和Identity Block**。
- Conv Block输入和输出的维度是不一样的，所以不能连续串联，它的作用是改变网络的维度；
- Identity Block输入维度和输出维度相同，可以串联，用于加深网络的。

Bottleneck：
- 1 x 1卷积压缩通道数
- 3 x 3卷积特征提取
- 1 x 1卷积扩张通道数
- 如果残差边有卷积就对残差边卷积再相加
- 如果残差边无卷积就直接相加

代码中[3, 4, 6, 3]对应的是block个数，makelayer实现conv block和identity block，每一次makelayer之后wh都被压缩为1/2，通道2倍。
利用主干特征提取的结果和第五次压缩的结果进行特征提取。

事实上就是残差网络的堆叠。

# 3. RPN建议框网络构建

- 先进行一个3 x 3的卷积，可理解为特征整合
- 1 x 1卷积，回归预测对先验框进行调整
> 用于预测 **公用特征层上** **每一个网格点上 每一个先验框**的变化情况。**Faster-RCNN的预测结果需要结合先验框获得预测框**。
- 1 x 1卷积，分类预测先验框内部是否包含物体
> 用于预测 **公用特征层上** **每一个网格点上** **每一个预测框**内部是否包含了物体。
生成先验框

# 4. 先验框

9个先验框。
feat_stride = 16，相当于图片上每16个像素点有一个网格。

# 5. 对先验框进行调整获得建议框

建议框：对图片上的目标进行粗筛，之后分类会对建议框内部物体进行判断，并且对建议框进一步调整。

建议框网络的预测结果分为两部分：
- 先验框的调整参数
- 先验框的得分
利用先验框的调整参数对先验框进行调整，利用得分判断是否包含物体。

筛选建议框，进行一些处理。
不断取出置信度最高的建议框，然后和其他的进行iou计算。
选出前三百个得分最高的建议框，然后返回筛选完的建议框。

# 6. ROIPooling层介绍-利用建议框截取公用特征层

给FM分区域，分别进行最大池化。
官方封装好了。

通过主干特征提取网络，我们可以获得一个公用特征层，当输入图片为600x600x3的时候，它的shape是38x38x1024，然后建议框会对这个公用特征层进行截取。
**其实公用特征层里面的38x38对应着图片里的38x38个区域，38x38中的每一个点相当于这个区域内部所有特征的浓缩。**
建议框会对这38x38个区域进行截取，也就是认为这些区域里存在目标，然后将截取的结果进行resize，resize到14x14x1024的大小。

然后再对每个建议框再进行Resnet原有的第五次压缩。压缩完后进行一个平均池化，再进行一个Flatten，最后分别进行一个num_classes的全连接和(num_classes)x4全连接。

num_classes的全连接用于对最后获得的框进行分类，(num_classes)x4全连接用于对相应的建议框进行调整。

通过这些操作，我们可以获得所有建议框的调整情况，和这个建议框调整后框内物体的类别。

![[Pasted image 20230306155013.png]]


# 7. 预测过程

frcnn中的detect_image，输入是一张图片。
1. 计算输入图片的高和宽
2. 计算resize后图片的大小，短边为600
3. 转换为RGB图片
4. 给原图像进行resize
5. 图像归一化->调整通道到第一维度->添加batch_size维度
6. 图片转为tensor，判断是否使用gpu
7. 图片传入网络中进行预测，获得预测结果（建议框调整参数，建议框种类得分，建议框坐标）
8. 利用classifier的预测结果对建议框进行解码，获得预测框
	1. 对建议框reshape，调整成（batch_size, 建议框的数量, 建议框的坐标）
	2. 对每张图片进行循环（由于在predict.py的时候，我们只输入一张图片，所以for-i- in range(len(mbox_ loc))只进行一次）
		1. 首先对回归参数乘一个系数（之前指定好的，作用就是改变数据的数量级）
		2. 回归参数reshape，建议框的数量, 建议框的种类，每个种类的调整参数
		3. 对获取到的建议框reshape，num_rois, 4 ->num_rois, 1, 4 -> 拓张成num_rois, num_classes, 4。（简单点说就是用建议框调整参数调整建议框获得预测框）
			1. 首先获得建议框宽高、中心xy坐标
			2. 取出xywh的调整参数
			3. 中心调整参数 * 建议框wh  + 建议框中心 -> 预测框中心；宽高调整参数取指数 * 建议框宽高 -> 预测框宽高
			4. 调整成左上角右下角的形式并返回
		4. 对调整后的结果再进行reshape，是相对于输入图片的，再进行归一化调整到01之间
		5. 获得种类得分并softmax，相当于获得概率
		6. 对种类循环（由于0号位置代表背景的概率所以从1取起）
			1. 取出属于该类的所有框的置信度，判断是否大于门限
			2. 将具体的预测框坐标和置信度取出
			3. 非极大值抑制
			4. 预测框坐标、置信度、种类堆叠
			5. 添加到结果中
		7. 调整到相对于原图的
9. 解码后的结果是否包含物体，不包含则返回原图，包含的话对预测结果进行切分
10. 图像绘制并返回
